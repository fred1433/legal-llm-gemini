# ğŸ›ï¸ Prototype LLM Juridique

## ğŸ“‹ Description

Prototype d'application web dÃ©montrant les capacitÃ©s d'un Large Language Model (Gemini 2.5) pour des tÃ¢ches juridiques. L'application comprend :

- **ğŸ›ï¸ Frontend statique** : Interface web moderne avec HTML5, CSS3 et JavaScript Vanilla
- **âš¡ Backend API** : API REST avec FastAPI, intÃ©gration Gemini et RAG avec FAISS
- **ğŸ¯ Trois fonctionnalitÃ©s principales** :
  1. ğŸ“„ GÃ©nÃ©ration de documents juridiques
  2. ğŸ” Recherche juridique avec RAG
  3. ğŸ’¬ Assistant virtuel conversationnel

## ğŸ—ï¸ Architecture

```
proto_llm_juridique/
â”œâ”€â”€ frontend/                 # Application web statique
â”‚   â”œâ”€â”€ index.html           # Page principale
â”‚   â”œâ”€â”€ css/style.css        # Styles personnalisÃ©s
â”‚   â””â”€â”€ js/
â”‚       â”œâ”€â”€ main.js          # Logique principale
â”‚       â””â”€â”€ api_config.js    # Configuration API
â””â”€â”€ backend/                 # API FastAPI
    â”œâ”€â”€ main.py              # Application principale
    â”œâ”€â”€ requirements.txt     # DÃ©pendances Python
    â”œâ”€â”€ .env                 # Variables d'environnement
    â”œâ”€â”€ app/
    â”‚   â”œâ”€â”€ api_v1/          # Endpoints API v1
    â”‚   â”œâ”€â”€ core/            # Configuration
    â”‚   â”œâ”€â”€ models/          # SchÃ©mas Pydantic
    â”‚   â””â”€â”€ services/        # Services mÃ©tier
    â””â”€â”€ data/                # Documents pour RAG
```

## ğŸš€ Installation et Lancement Local

### PrÃ©requis

- Python 3.9+
- Node.js (pour Surge.sh uniquement)
- Extension VS Code "Live Server" (recommandÃ©e)

### 1. Configuration du Backend

```bash
# Naviguer vers le dossier backend
cd backend

# CrÃ©er un environnement virtuel
python -m venv venv

# Activer l'environnement virtuel
# Sur macOS/Linux :
source venv/bin/activate
# Sur Windows :
# venv\Scripts\activate

# Installer les dÃ©pendances
pip install -r requirements.txt

# Configurer la clÃ© API Gemini
# Ã‰diter le fichier .env et remplacer VOTRE_CLÃ‰_API_ICI par votre vraie clÃ© API
```

### 2. Obtenir une clÃ© API Gemini

1. Aller sur [Google AI Studio](https://makersuite.google.com/app/apikey)
2. CrÃ©er une nouvelle clÃ© API
3. Copier la clÃ© dans le fichier `backend/.env`

### 3. Lancer le Backend

```bash
# Depuis le dossier backend/
uvicorn main:app --reload --port 8000
```

Le backend sera accessible sur `http://localhost:8000`
- Documentation API : `http://localhost:8000/docs`
- Health check : `http://localhost:8000/health`

### 4. Lancer le Frontend

**Option 1 : Live Server (RecommandÃ©e)**
1. Ouvrir le dossier `frontend/` dans VS Code
2. Clic droit sur `index.html` â†’ "Open with Live Server"
3. L'application s'ouvre sur `http://localhost:5500`

**Option 2 : Serveur HTTP simple**
```bash
# Depuis le dossier frontend/
python -m http.server 8080
# Puis aller sur http://localhost:8080
```

## ğŸ§ª Test des FonctionnalitÃ©s

### GÃ©nÃ©ration de Documents
1. SÃ©lectionner "Contrat de travail"
2. Remplir les champs (employeur, employÃ©, poste, salaire)
3. Cliquer "GÃ©nÃ©rer le document"

### Recherche Juridique
1. Poser une question comme : "Quelle est la durÃ©e maximale de la pÃ©riode d'essai ?"
2. Voir la rÃ©ponse avec les sources consultÃ©es

### Chat Assistant
1. Taper un message comme : "Expliquez-moi la responsabilitÃ© contractuelle"
2. Converser avec l'assistant

## ğŸ“± DÃ©ploiement

### Backend sur Render

1. **PrÃ©parer le Repository**
   ```bash
   # CrÃ©er un nouveau repo GitHub avec le contenu du dossier backend/
   ```

2. **DÃ©ployer sur Render**
   - Aller sur [render.com](https://render.com)
   - CrÃ©er un nouveau "Web Service"
   - Connecter votre repo GitHub
   - Configuration :
     - **Name** : `proto-llm-juridique-api`
     - **Region** : Europe (Frankfurt)
     - **Branch** : `main`
     - **Runtime** : Python 3
     - **Build Command** : `pip install -r requirements.txt`
     - **Start Command** : `uvicorn main:app --host 0.0.0.0 --port $PORT`

3. **Variables d'Environnement**
   - `GEMINI_API_KEY` : Votre clÃ© API Gemini
   - `PYTHON_VERSION` : `3.9.12`

### Frontend sur Surge.sh

1. **Configurer l'URL du Backend**
   ```javascript
   // Dans frontend/js/api_config.js
   const API_BASE_URL = 'https://VOTRE-APP-RENDER.onrender.com/api/v1';
   ```

2. **DÃ©ployer avec Surge**
   ```bash
   # Installer Surge CLI
   npm install --global surge
   
   # Depuis le dossier frontend/
   cd frontend
   surge
   
   # Suivre les instructions (choisir un domaine)
   ```

3. **Mettre Ã  jour CORS**
   - Ajouter l'URL Surge dans `backend/main.py` :
   ```python
   origins = [
       "https://votre-site.surge.sh",
       # ... autres origins
   ]
   ```
   - RedÃ©ployer le backend

## ğŸ”§ Configuration AvancÃ©e

### Utilisation avec une vraie clÃ© Gemini

Pour utiliser Gemini au lieu des donnÃ©es factices :

1. Obtenir une clÃ© API sur [Google AI Studio](https://makersuite.google.com/app/apikey)
2. Remplacer dans `.env` :
   ```
   GEMINI_API_KEY="votre_vraie_cle_api"
   ```
3. RedÃ©marrer le backend

### Ajouter des documents pour RAG

1. Placer des fichiers `.txt` dans `backend/data/`
2. RedÃ©marrer le backend (les documents sont chargÃ©s au dÃ©marrage)

## ğŸ“Š Structure des DonnÃ©es

### GÃ©nÃ©ration de Documents
```json
{
  "type_document": "contrat",
  "parametres": {
    "employeur": "Entreprise ABC",
    "employe": "Jean Dupont",
    "poste": "DÃ©veloppeur",
    "salaire": "3000"
  }
}
```

### Recherche Juridique
```json
{
  "question": "Quelle est la durÃ©e de la pÃ©riode d'essai ?"
}
```

### Chat
```json
{
  "message": "Expliquez la responsabilitÃ© contractuelle",
  "historique": [...]
}
```

## âš ï¸ Limitations et Notes

- **DÃ©monstration uniquement** : Ne constitue pas un conseil juridique
- **DonnÃ©es factices** : Sans clÃ© Gemini, utilise des rÃ©ponses prÃ©programmÃ©es
- **RAG simplifiÃ©** : Embeddings alÃ©atoires pour la dÃ©mo
- **SÃ©curitÃ©** : Pas d'authentification (prototype uniquement)

## ğŸ› DÃ©pannage

### Le backend ne dÃ©marre pas
- VÃ©rifier que l'environnement virtuel est activÃ©
- Installer les dÃ©pendances : `pip install -r requirements.txt`
- VÃ©rifier le port 8000 est libre

### Le frontend ne se connecte pas au backend
- VÃ©rifier que le backend fonctionne sur `http://localhost:8000`
- VÃ©rifier l'URL dans `frontend/js/api_config.js`
- Ouvrir la console du navigateur pour voir les erreurs

### Erreurs CORS
- VÃ©rifier la configuration CORS dans `backend/main.py`
- Ajouter l'URL du frontend aux origins autorisÃ©es

## ğŸ“„ License

Ce projet est un prototype Ã©ducatif. Utilisation libre pour l'apprentissage et la dÃ©monstration.

## ğŸ¤ Contact

Pour toute question concernant ce prototype, veuillez consulter la documentation ou les logs d'erreur dans la console du navigateur.

---

**âš¡ Powered by FastAPI, Gemini 2.5, and Modern Web Technologies** 